{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8ac2a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,glob,sys\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV\n",
    "import dask\n",
    "from direct_effect_analysis import DirectEffectAnalysis\n",
    "sys.path.append('../')\n",
    "from linear_regression import get_slope_and_pval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113ac0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--run_train\", type=str)\n",
    "parser.add_argument(\"--run_test\", type=str)\n",
    "parser.add_argument(\"--period\", type=str)\n",
    "args = parser.parse_args()\n",
    "for k,v in vars(args).items():\n",
    "    globals()[k] = v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f72aaec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_train = '1300'\n",
    "run_test = '1400'\n",
    "period = '1979-2023'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4069f4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ppfleiderer/miniforge3/envs/py_gmlnet/lib/python3.9/site-packages/xarray/core/indexing.py:1446: PerformanceWarning: Slicing with an out-of-order index is generating 45 times more chunks\n",
      "  return self.array[key]\n",
      "/home/ppfleiderer/miniforge3/envs/py_gmlnet/lib/python3.9/site-packages/xarray/core/indexing.py:1446: PerformanceWarning: Slicing with an out-of-order index is generating 45 times more chunks\n",
      "  return self.array[key]\n",
      "/home/ppfleiderer/miniforge3/envs/py_gmlnet/lib/python3.9/site-packages/xarray/core/indexing.py:1446: PerformanceWarning: Slicing with an out-of-order index is generating 45 times more chunks\n",
      "  return self.array[key]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define summer months (June, July, August)\n",
    "summer_months = [6, 7, 8]\n",
    "gmst_rolling_window_size_in_days = 30\n",
    "y1,y2 = period.split('-')\n",
    "\n",
    "def preprocessing(nc):\n",
    "    with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
    "        nc = nc.sel(time=nc['time.year'].isin(np.arange(int(y1), int(y2)+1, 1)))\n",
    "    return nc\n",
    "\n",
    "def get_histssp370_files(var, run):\n",
    "    fls = []\n",
    "    if int(y1) < 2015 and int(y2) >= 2015:\n",
    "        compsets = ['b.e212.BHISTcmip6.f09_g17','b.e212.BSSP370cmip6.f09_g17']\n",
    "    elif int(y1) >= 2015:\n",
    "        compsets = ['b.e212.BSSP370cmip6.f09_g17']\n",
    "\n",
    "    for compset in compsets:\n",
    "        fl = f\"/climca/data/CESM2-ETH/{compset}.{run}/{var}_day_{compset}.{run}.nc\"\n",
    "        if os.path.isfile(fl):\n",
    "            fls += [fl]\n",
    "    return fls\n",
    "\n",
    "def get_nudged_files(var, run):\n",
    "    compset = 'b.e212.B1850cmip6.f09_g17.001.nudge-1850-2100-SSP370'\n",
    "    fl = f'/climca/data/CESM2-ETH/{compset}.{run}.linear-weak/{var}_day_{compset}.{run}.linear-weak.nc'\n",
    "    if os.path.isfile(fl):\n",
    "        return fl\n",
    "\n",
    "with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
    "    nc_trefht_recent = xr.open_mfdataset(get_histssp370_files('TREFHT', run_train), preprocess=preprocessing)\n",
    "    trefht_recent = nc_trefht_recent.sel(time=nc_trefht_recent['time.month'].isin(summer_months))\n",
    "    \n",
    "    nc_trefht_nudge = xr.open_mfdataset(get_nudged_files('TREFHT', run_train), preprocess=preprocessing)\n",
    "    trefht_nudge = nc_trefht_nudge.sel(time=nc_trefht_nudge['time.month'].isin(summer_months))\n",
    "    \n",
    "    nc_z500_recent = xr.open_mfdataset(get_histssp370_files('Z500', run_train), preprocess=preprocessing)\n",
    "    c = 6 # Coarsening the atmospheric circulation to avoid overfitting\n",
    "    z500_recent = nc_z500_recent['Z500'].sel(time=nc_z500_recent['time.month'].isin(summer_months)).coarsen(lat=c, lon=c, boundary='trim').mean()\n",
    "    z500_global_mean = nc_z500_recent['Z500'].sel(time=nc_z500_recent['time.month'].isin(summer_months)).weighted(np.cos(np.radians(nc_z500_recent.lat))).mean(('lat','lon'))\n",
    "    z500_recent -= z500_global_mean\n",
    "\n",
    "# select relevant grid-cells\n",
    "trefht_recent = trefht_recent.sel(lat=slice(30, 70))\n",
    "trefht_nudge = trefht_nudge.sel(lat=slice(30, 70))\n",
    "z500_recent = z500_recent.sel(lat=slice(-10, 90))\n",
    "\n",
    "# remove seasonality\n",
    "z500_recent = (z500_recent.groupby('time.month') - z500_recent.groupby('time.month').mean())\n",
    "trefht_recent = (trefht_recent.groupby('time.month') - trefht_recent.groupby('time.month').mean())\n",
    "trefht_nudge = (trefht_nudge.groupby('time.month') - trefht_nudge.groupby('time.month').mean())\n",
    "\n",
    "gmst_recent = nc_trefht_recent.weighted(np.cos(np.radians(nc_trefht_recent.lat))).mean(('lat','lon'))\n",
    "gmst_recent = gmst_recent.rolling(time=gmst_rolling_window_size_in_days, center=True).mean()\n",
    "gmst_recent = gmst_recent.sel(time=nc_trefht_recent['time.month'].isin(summer_months))['TREFHT'].data[:, None]\n",
    "\n",
    "gmst_nudge = nc_trefht_nudge.weighted(np.cos(np.radians(nc_trefht_nudge.lat))).mean(('lat','lon'))\n",
    "gmst_nudge = gmst_nudge.rolling(time=gmst_rolling_window_size_in_days, center=True).mean()\n",
    "gmst_nudge = gmst_nudge.sel(time=nc_trefht_recent['time.month'].isin(summer_months))['TREFHT'].data[:, None]\n",
    "\n",
    "gmst_recent = gmst_recent - gmst_recent.mean()\n",
    "gmst_nudge = gmst_nudge - gmst_nudge.mean()\n",
    "\n",
    "# Saving lat, lon and time\n",
    "lats = trefht_recent.lat.data\n",
    "lons = trefht_recent.lon.data\n",
    "time = trefht_recent.time.data\n",
    "\n",
    "# Converting xarray to numpy array of correct dimensions\n",
    "X_2d = z500_recent.values.reshape((len(time), -1))\n",
    "Y_2d = trefht_recent.TREFHT.values.reshape((len(time), -1))\n",
    "\n",
    "# training\n",
    "X_train, X_test, Y_train, Y_test, Z_train, Z_test = train_test_split(X_2d, Y_2d, gmst_recent, test_size=0.2)\n",
    "n_cps = np.logspace(0.15, 2.2, 20).astype('int')\n",
    "dea = DirectEffectAnalysis(n_components='optimal', n_cps=n_cps, k_fold=5)\n",
    "dea.fit(X_train, Y_train, Z_train, fit_test=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46a3a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_gmlnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
